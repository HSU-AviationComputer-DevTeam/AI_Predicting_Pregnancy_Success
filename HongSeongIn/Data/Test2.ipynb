{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV, StratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import StackingClassifier, ExtraTreesClassifier, RandomForestClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "import scipy.stats as stats\n",
    "\n",
    "# üîπ train_test_splitÏùÑ import Ï∂îÍ∞Ä\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# ‚úÖ Î¨∏ÏûêÏó¥ ‚Üí Ïà´ÏûêÎ°ú Î≥ÄÌôòÌïòÎäî Ìï®Ïàò (ÌöüÏàò Îç∞Ïù¥ÌÑ∞ Î≥ÄÌôò)\n",
    "def convert_count_str(val):\n",
    "    if pd.isna(val):\n",
    "        return 0\n",
    "    val = str(val).strip()\n",
    "    if \"Ìöå Ïù¥ÏÉÅ\" in val:\n",
    "        return 6\n",
    "    m = re.search(r'(\\d+)Ìöå?', val)\n",
    "    return int(m.group(1)) if m else 0\n",
    "\n",
    "# ‚úÖ Ï†ïÏûê, ÎÇúÏûê Í∏∞Ï¶ùÏûê ÎÇòÏù¥ Îß§Ìïë\n",
    "donor_age_mapping = {\n",
    "    'Îßå20ÏÑ∏ Ïù¥Ìïò': 3, 'Îßå21-25ÏÑ∏': 5, 'Îßå26-30ÏÑ∏': 4, 'Îßå31-35ÏÑ∏': 2,\n",
    "    'Îßå36-40ÏÑ∏': 1, 'Îßå41-45ÏÑ∏': 0, 'Ïïå Ïàò ÏóÜÏùå': 0\n",
    "}\n",
    "\n",
    "def convert_donor_age(val):\n",
    "    if pd.isna(val):\n",
    "        return np.nan\n",
    "    return donor_age_mapping.get(str(val).strip(), np.nan)\n",
    "\n",
    "# ‚úÖ NaNÏùÑ Î¨∏ÏûêÏó¥ 'NaN'ÏúºÎ°ú Î≥ÄÌôòÌïòÎäî Ìï®Ïàò (Ïπ¥ÌÖåÍ≥†Î¶¨Ìòï Î≥ÄÏàò Ï≤òÎ¶¨)\n",
    "def convert_nan_to_string(df, category_columns):\n",
    "    df_copy = df.copy()\n",
    "    for col in category_columns:\n",
    "        df_copy[col] = df_copy[col].fillna('NaN').astype(\"category\")\n",
    "    return df_copy\n",
    "\n",
    "# ‚úÖ Í∞ÄÏ§ëÏπò Ï†ÅÏö© Ìï®Ïàò (Î™®Îì† ÏãúÏà† Ïú†Ìòï Î∞òÏòÅ)\n",
    "def apply_feature_weights(X, weight_dict):\n",
    "    X_weighted = X.copy()\n",
    "    for category, weights in weight_dict.items():  # Î™®Îì† ÏãúÏà† Ïú†Ìòï(IVF, DI Îì±) ÏàúÌöå\n",
    "        for column in X.columns:\n",
    "            if column in weights:  # Ìï¥Îãπ Ïπ¥ÌÖåÍ≥†Î¶¨Ïóê Í∞ÄÏ§ëÏπòÍ∞Ä ÏûàÏúºÎ©¥ Ï†ÅÏö©\n",
    "                X_weighted[column] *= weights[column]\n",
    "    return X_weighted\n",
    "\n",
    "# ‚úÖ 1. Îç∞Ïù¥ÌÑ∞ Î°úÎìú\n",
    "train = pd.read_csv('train.csv').drop(columns=['ID'])\n",
    "test = pd.read_csv('test.csv').drop(columns=['ID'])\n",
    "\n",
    "# ‚úÖ 2. Í∞ÄÏ§ëÏπò Îç∞Ïù¥ÌÑ∞ Î°úÎìú (Î™®Îì† ÏãúÏà† Ïú†Ìòï Î∞òÏòÅ)\n",
    "weight_data = pd.read_csv('og_weighted_hong.csv', encoding='utf-8')\n",
    "weight_dict = weight_data.set_index(\"Îç∞Ïù¥ÌÑ∞ Ìï≠Î™©\").to_dict()\n",
    "\n",
    "# ‚úÖ 3. ÏãúÏà† ÎãπÏãú ÎÇòÏù¥ Î≥ÄÌôò\n",
    "age_mapping = {\n",
    "    'Îßå18-34ÏÑ∏': 5, 'Îßå35-37ÏÑ∏': 4, 'Îßå38-39ÏÑ∏': 3, 'Îßå40-42ÏÑ∏': 2, 'Îßå43-44ÏÑ∏': 1, 'Îßå45-50ÏÑ∏': 0, 'Ïïå Ïàò ÏóÜÏùå': np.nan\n",
    "}\n",
    "train['ÏãúÏà† ÎãπÏãú ÎÇòÏù¥'] = train['ÏãúÏà† ÎãπÏãú ÎÇòÏù¥'].map(lambda x: float(age_mapping.get(str(x).strip(), np.nan)))\n",
    "test['ÏãúÏà† ÎãπÏãú ÎÇòÏù¥'] = test['ÏãúÏà† ÎãπÏãú ÎÇòÏù¥'].map(lambda x: float(age_mapping.get(str(x).strip(), np.nan)))\n",
    "\n",
    "# ‚úÖ 4. ÌöüÏàò Í¥ÄÎ†® Ïª¨Îüº Î≥ÄÌôò\n",
    "count_columns = [\"Ï¥ù ÏãúÏà† ÌöüÏàò\", \"ÌÅ¥Î¶¨Îãâ ÎÇ¥ Ï¥ù ÏãúÏà† ÌöüÏàò\", \"IVF ÏãúÏà† ÌöüÏàò\", \"DI ÏãúÏà† ÌöüÏàò\",\n",
    "                 \"Ï¥ù ÏûÑÏã† ÌöüÏàò\", \"IVF ÏûÑÏã† ÌöüÏàò\", \"DI ÏûÑÏã† ÌöüÏàò\", \"Ï¥ù Ï∂úÏÇ∞ ÌöüÏàò\", \"IVF Ï∂úÏÇ∞ ÌöüÏàò\", \"DI Ï∂úÏÇ∞ ÌöüÏàò\"]\n",
    "\n",
    "for col in count_columns:\n",
    "    train[col] = train[col].astype(str).apply(convert_count_str).astype(int)\n",
    "    test[col] = test[col].astype(str).apply(convert_count_str).astype(int)\n",
    "\n",
    "# ‚úÖ 5. ÎÇúÏûê/Ï†ïÏûê Í∏∞Ï¶ùÏûê ÎÇòÏù¥ Î≥ÄÌôò\n",
    "train['ÎÇúÏûê Í∏∞Ï¶ùÏûê ÎÇòÏù¥'] = train['ÎÇúÏûê Í∏∞Ï¶ùÏûê ÎÇòÏù¥'].astype(str).apply(convert_donor_age)\n",
    "test['ÎÇúÏûê Í∏∞Ï¶ùÏûê ÎÇòÏù¥'] = test['ÎÇúÏûê Í∏∞Ï¶ùÏûê ÎÇòÏù¥'].astype(str).apply(convert_donor_age)\n",
    "train['Ï†ïÏûê Í∏∞Ï¶ùÏûê ÎÇòÏù¥'] = train['Ï†ïÏûê Í∏∞Ï¶ùÏûê ÎÇòÏù¥'].astype(str).apply(convert_donor_age)\n",
    "test['Ï†ïÏûê Í∏∞Ï¶ùÏûê ÎÇòÏù¥'] = test['Ï†ïÏûê Í∏∞Ï¶ùÏûê ÎÇòÏù¥'].astype(str).apply(convert_donor_age)\n",
    "\n",
    "# ‚úÖ 6. Feature Í∞ÄÏ§ëÏπò Ï†ÅÏö©\n",
    "X = train.drop('ÏûÑÏã† ÏÑ±Í≥µ Ïó¨Î∂Ä', axis=1)\n",
    "y = train['ÏûÑÏã† ÏÑ±Í≥µ Ïó¨Î∂Ä']\n",
    "\n",
    "X_weighted = apply_feature_weights(X, weight_dict)\n",
    "X_test_weighted = apply_feature_weights(test, weight_dict)\n",
    "\n",
    "# ‚úÖ 7. Îç∞Ïù¥ÌÑ∞ Î∂àÍ∑†Ìòï Ï≤òÎ¶¨ (ÏûÑÏã† ÏÑ±Í≥µ Ïó¨Î∂Ä Í∏∞Ï§Ä)\n",
    "undersample = RandomUnderSampler(sampling_strategy=0.5, random_state=42)\n",
    "X_resampled, y_resampled = undersample.fit_resample(X_weighted, y)\n",
    "\n",
    "# ‚úÖ 8. Î≤îÏ£ºÌòï Î≥ÄÏàò Î≥ÄÌôò\n",
    "category_columns = [\"ÏãúÏà† ÏãúÍ∏∞ ÏΩîÎìú\", \"ÏãúÏà† Ïú†Ìòï\", \"ÌäπÏ†ï ÏãúÏà† Ïú†Ìòï\", \"Î∞∞ÎûÄ Ïú†ÎèÑ Ïú†Ìòï\",\n",
    "                    \"Î∞∞ÏïÑ ÏÉùÏÑ± Ï£ºÏöî Ïù¥Ïú†\", \"ÎÇúÏûê Ï∂úÏ≤ò\", \"Ï†ïÏûê Ï∂úÏ≤ò\", \"ÎÇúÏûê Í∏∞Ï¶ùÏûê ÎÇòÏù¥\", \"Ï†ïÏûê Í∏∞Ï¶ùÏûê ÎÇòÏù¥\"]\n",
    "\n",
    "X_resampled = convert_nan_to_string(X_resampled, category_columns)\n",
    "X_test_weighted = convert_nan_to_string(X_test_weighted, category_columns)\n",
    "\n",
    "# ‚úÖ 9. Îç∞Ïù¥ÌÑ∞ Î∂ÑÌï†\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_resampled, y_resampled,\n",
    "                                                  test_size=0.2, random_state=42, stratify=y_resampled)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV, StratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import StackingClassifier, ExtraTreesClassifier, RandomForestClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "import scipy.stats as stats\n",
    "\n",
    "# üîπ train_test_splitÏùÑ import Ï∂îÍ∞Ä\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_resampled' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 18\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mcatboost\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m CatBoostClassifier\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# ‚úÖ Î™®Îç∏ Íµ¨ÏÑ±\u001b[39;00m\n\u001b[0;32m     14\u001b[0m stack_clf \u001b[38;5;241m=\u001b[39m StackingClassifier(\n\u001b[0;32m     15\u001b[0m     estimators\u001b[38;5;241m=\u001b[39m[\n\u001b[0;32m     16\u001b[0m         (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mxgb\u001b[39m\u001b[38;5;124m'\u001b[39m, XGBClassifier(tree_method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgpu_hist\u001b[39m\u001b[38;5;124m'\u001b[39m, enable_categorical\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)),\n\u001b[0;32m     17\u001b[0m         (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlgbm\u001b[39m\u001b[38;5;124m'\u001b[39m, LGBMClassifier(n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)),\n\u001b[1;32m---> 18\u001b[0m         (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcat\u001b[39m\u001b[38;5;124m'\u001b[39m, CatBoostClassifier(task_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mGPU\u001b[39m\u001b[38;5;124m'\u001b[39m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, cat_features\u001b[38;5;241m=\u001b[39m[X_resampled\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mget_loc(c) \u001b[38;5;28;01mfor\u001b[39;00m c \u001b[38;5;129;01min\u001b[39;00m category_columns]))\n\u001b[0;32m     19\u001b[0m     ],\n\u001b[0;32m     20\u001b[0m     final_estimator\u001b[38;5;241m=\u001b[39mPipeline([\n\u001b[0;32m     21\u001b[0m         (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mscaler\u001b[39m\u001b[38;5;124m'\u001b[39m, RobustScaler()),\n\u001b[0;32m     22\u001b[0m         (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlr\u001b[39m\u001b[38;5;124m'\u001b[39m, LogisticRegression(max_iter\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1000\u001b[39m, class_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbalanced\u001b[39m\u001b[38;5;124m'\u001b[39m, solver\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mliblinear\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[0;32m     23\u001b[0m     ]),\n\u001b[0;32m     24\u001b[0m     cv\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m,\n\u001b[0;32m     25\u001b[0m     n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m\n\u001b[0;32m     26\u001b[0m )\n\u001b[0;32m     28\u001b[0m \u001b[38;5;66;03m# ‚úÖ Î™®Îç∏ ÌïôÏäµ\u001b[39;00m\n\u001b[0;32m     29\u001b[0m stack_clf\u001b[38;5;241m.\u001b[39mfit(X_train, y_train)\n",
      "Cell \u001b[1;32mIn[8], line 18\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mcatboost\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m CatBoostClassifier\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# ‚úÖ Î™®Îç∏ Íµ¨ÏÑ±\u001b[39;00m\n\u001b[0;32m     14\u001b[0m stack_clf \u001b[38;5;241m=\u001b[39m StackingClassifier(\n\u001b[0;32m     15\u001b[0m     estimators\u001b[38;5;241m=\u001b[39m[\n\u001b[0;32m     16\u001b[0m         (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mxgb\u001b[39m\u001b[38;5;124m'\u001b[39m, XGBClassifier(tree_method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgpu_hist\u001b[39m\u001b[38;5;124m'\u001b[39m, enable_categorical\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)),\n\u001b[0;32m     17\u001b[0m         (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlgbm\u001b[39m\u001b[38;5;124m'\u001b[39m, LGBMClassifier(n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)),\n\u001b[1;32m---> 18\u001b[0m         (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcat\u001b[39m\u001b[38;5;124m'\u001b[39m, CatBoostClassifier(task_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mGPU\u001b[39m\u001b[38;5;124m'\u001b[39m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, cat_features\u001b[38;5;241m=\u001b[39m[\u001b[43mX_resampled\u001b[49m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mget_loc(c) \u001b[38;5;28;01mfor\u001b[39;00m c \u001b[38;5;129;01min\u001b[39;00m category_columns]))\n\u001b[0;32m     19\u001b[0m     ],\n\u001b[0;32m     20\u001b[0m     final_estimator\u001b[38;5;241m=\u001b[39mPipeline([\n\u001b[0;32m     21\u001b[0m         (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mscaler\u001b[39m\u001b[38;5;124m'\u001b[39m, RobustScaler()),\n\u001b[0;32m     22\u001b[0m         (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlr\u001b[39m\u001b[38;5;124m'\u001b[39m, LogisticRegression(max_iter\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1000\u001b[39m, class_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbalanced\u001b[39m\u001b[38;5;124m'\u001b[39m, solver\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mliblinear\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[0;32m     23\u001b[0m     ]),\n\u001b[0;32m     24\u001b[0m     cv\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m,\n\u001b[0;32m     25\u001b[0m     n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m\n\u001b[0;32m     26\u001b[0m )\n\u001b[0;32m     28\u001b[0m \u001b[38;5;66;03m# ‚úÖ Î™®Îç∏ ÌïôÏäµ\u001b[39;00m\n\u001b[0;32m     29\u001b[0m stack_clf\u001b[38;5;241m.\u001b[39mfit(X_train, y_train)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X_resampled' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "#  1. Îç∞Ïù¥ÌÑ∞ Î°úÎìú Î∞è Ï†ÑÏ≤òÎ¶¨\n",
    "train = pd.read_csv('train.csv').drop(columns=['ID'])\n",
    "test = pd.read_csv('test.csv').drop(columns=['ID'])\n",
    "\n",
    "# ‚úÖ train_test_split Ïò§Î•ò Ìï¥Í≤∞\n",
    "X = train.drop('ÏûÑÏã† ÏÑ±Í≥µ Ïó¨Î∂Ä', axis=1)\n",
    "y = train['ÏûÑÏã† ÏÑ±Í≥µ Ïó¨Î∂Ä']\n",
    "\n",
    "# Îç∞Ïù¥ÌÑ∞ Î∂ÑÌï† (ÏàòÏ†ïÎêú Î∂ÄÎ∂Ñ)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "\n",
    "# ‚úÖ Î™®Îç∏ Íµ¨ÏÑ±\n",
    "stack_clf = StackingClassifier(\n",
    "    estimators=[\n",
    "        ('xgb', XGBClassifier(tree_method='gpu_hist', enable_categorical=True, random_state=42)),\n",
    "        ('lgbm', LGBMClassifier(n_jobs=1, random_state=42, verbose=-1)),\n",
    "        ('cat', CatBoostClassifier(task_type='GPU', verbose=0, cat_features=[X_resampled.columns.get_loc(c) for c in category_columns]))\n",
    "    ],\n",
    "    final_estimator=Pipeline([\n",
    "        ('scaler', RobustScaler()),\n",
    "        ('lr', LogisticRegression(max_iter=1000, class_weight='balanced', solver='liblinear'))\n",
    "    ]),\n",
    "    cv=3,\n",
    "    n_jobs=1\n",
    ")\n",
    "\n",
    "# ‚úÖ Î™®Îç∏ ÌïôÏäµ\n",
    "stack_clf.fit(X_train, y_train)\n",
    "\n",
    "# ‚úÖ Í≤ÄÏ¶ù Îç∞Ïù¥ÌÑ∞ ÌèâÍ∞Ä\n",
    "y_val_pred = stack_clf.predict_proba(X_val)[:, 1]\n",
    "roc_auc = roc_auc_score(y_val, y_val_pred)\n",
    "print(f\"Validation ROC AUC: {roc_auc:.5f}\")\n",
    "\n",
    "# ‚úÖ ÌÖåÏä§Ìä∏ Îç∞Ïù¥ÌÑ∞ ÏòàÏ∏°\n",
    "pred_proba = stack_clf.predict_proba(X_test_weighted)[:, 1]\n",
    "\n",
    "# ‚úÖ Í≤∞Í≥º Ï†ÄÏû•\n",
    "submission = pd.DataFrame({'ID': [f\"TEST_{i:05d}\" for i in range(len(test))],'probability': pred_proba})\n",
    "submission.to_csv('/content/drive/MyDrive/aimers/submit/final_model_submit.csv', index=False)\n",
    "print(\"Ï†úÏ∂ú ÌååÏùº ÏÉùÏÑ± ÏôÑÎ£å\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
