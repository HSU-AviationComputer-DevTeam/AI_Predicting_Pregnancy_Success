{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV, StratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import StackingClassifier, ExtraTreesClassifier, RandomForestClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "import scipy.stats as stats\n",
    "\n",
    "# 🔹 train_test_split을 import 추가\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# ✅ 문자열 → 숫자로 변환하는 함수 (횟수 데이터 변환)\n",
    "def convert_count_str(val):\n",
    "    if pd.isna(val):\n",
    "        return 0\n",
    "    val = str(val).strip()\n",
    "    if \"회 이상\" in val:\n",
    "        return 6\n",
    "    m = re.search(r'(\\d+)회?', val)\n",
    "    return int(m.group(1)) if m else 0\n",
    "\n",
    "# ✅ 정자, 난자 기증자 나이 매핑\n",
    "donor_age_mapping = {\n",
    "    '만20세 이하': 3, '만21-25세': 5, '만26-30세': 4, '만31-35세': 2,\n",
    "    '만36-40세': 1, '만41-45세': 0, '알 수 없음': 0\n",
    "}\n",
    "\n",
    "def convert_donor_age(val):\n",
    "    if pd.isna(val):\n",
    "        return np.nan\n",
    "    return donor_age_mapping.get(str(val).strip(), np.nan)\n",
    "\n",
    "# ✅ NaN을 문자열 'NaN'으로 변환하는 함수 (카테고리형 변수 처리)\n",
    "def convert_nan_to_string(df, category_columns):\n",
    "    df_copy = df.copy()\n",
    "    for col in category_columns:\n",
    "        df_copy[col] = df_copy[col].fillna('NaN').astype(\"category\")\n",
    "    return df_copy\n",
    "\n",
    "# ✅ 가중치 적용 함수 (모든 시술 유형 반영)\n",
    "def apply_feature_weights(X, weight_dict):\n",
    "    X_weighted = X.copy()\n",
    "    for category, weights in weight_dict.items():  # 모든 시술 유형(IVF, DI 등) 순회\n",
    "        for column in X.columns:\n",
    "            if column in weights:  # 해당 카테고리에 가중치가 있으면 적용\n",
    "                X_weighted[column] *= weights[column]\n",
    "    return X_weighted\n",
    "\n",
    "# ✅ 1. 데이터 로드\n",
    "train = pd.read_csv('train.csv').drop(columns=['ID'])\n",
    "test = pd.read_csv('test.csv').drop(columns=['ID'])\n",
    "\n",
    "# ✅ 2. 가중치 데이터 로드 (모든 시술 유형 반영)\n",
    "weight_data = pd.read_csv('og_weighted_hong.csv', encoding='utf-8')\n",
    "weight_dict = weight_data.set_index(\"데이터 항목\").to_dict()\n",
    "\n",
    "# ✅ 3. 시술 당시 나이 변환\n",
    "age_mapping = {\n",
    "    '만18-34세': 5, '만35-37세': 4, '만38-39세': 3, '만40-42세': 2, '만43-44세': 1, '만45-50세': 0, '알 수 없음': np.nan\n",
    "}\n",
    "train['시술 당시 나이'] = train['시술 당시 나이'].map(lambda x: float(age_mapping.get(str(x).strip(), np.nan)))\n",
    "test['시술 당시 나이'] = test['시술 당시 나이'].map(lambda x: float(age_mapping.get(str(x).strip(), np.nan)))\n",
    "\n",
    "# ✅ 4. 횟수 관련 컬럼 변환\n",
    "count_columns = [\"총 시술 횟수\", \"클리닉 내 총 시술 횟수\", \"IVF 시술 횟수\", \"DI 시술 횟수\",\n",
    "                 \"총 임신 횟수\", \"IVF 임신 횟수\", \"DI 임신 횟수\", \"총 출산 횟수\", \"IVF 출산 횟수\", \"DI 출산 횟수\"]\n",
    "\n",
    "for col in count_columns:\n",
    "    train[col] = train[col].astype(str).apply(convert_count_str).astype(int)\n",
    "    test[col] = test[col].astype(str).apply(convert_count_str).astype(int)\n",
    "\n",
    "# ✅ 5. 난자/정자 기증자 나이 변환\n",
    "train['난자 기증자 나이'] = train['난자 기증자 나이'].astype(str).apply(convert_donor_age)\n",
    "test['난자 기증자 나이'] = test['난자 기증자 나이'].astype(str).apply(convert_donor_age)\n",
    "train['정자 기증자 나이'] = train['정자 기증자 나이'].astype(str).apply(convert_donor_age)\n",
    "test['정자 기증자 나이'] = test['정자 기증자 나이'].astype(str).apply(convert_donor_age)\n",
    "\n",
    "# ✅ 6. Feature 가중치 적용\n",
    "X = train.drop('임신 성공 여부', axis=1)\n",
    "y = train['임신 성공 여부']\n",
    "\n",
    "X_weighted = apply_feature_weights(X, weight_dict)\n",
    "X_test_weighted = apply_feature_weights(test, weight_dict)\n",
    "\n",
    "# ✅ 7. 데이터 불균형 처리 (임신 성공 여부 기준)\n",
    "undersample = RandomUnderSampler(sampling_strategy=0.5, random_state=42)\n",
    "X_resampled, y_resampled = undersample.fit_resample(X_weighted, y)\n",
    "\n",
    "# ✅ 8. 범주형 변수 변환\n",
    "category_columns = [\"시술 시기 코드\", \"시술 유형\", \"특정 시술 유형\", \"배란 유도 유형\",\n",
    "                    \"배아 생성 주요 이유\", \"난자 출처\", \"정자 출처\", \"난자 기증자 나이\", \"정자 기증자 나이\"]\n",
    "\n",
    "X_resampled = convert_nan_to_string(X_resampled, category_columns)\n",
    "X_test_weighted = convert_nan_to_string(X_test_weighted, category_columns)\n",
    "\n",
    "# ✅ 9. 데이터 분할\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_resampled, y_resampled,\n",
    "                                                  test_size=0.2, random_state=42, stratify=y_resampled)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV, StratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import StackingClassifier, ExtraTreesClassifier, RandomForestClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "import scipy.stats as stats\n",
    "\n",
    "# 🔹 train_test_split을 import 추가\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_resampled' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 18\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mcatboost\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m CatBoostClassifier\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# ✅ 모델 구성\u001b[39;00m\n\u001b[0;32m     14\u001b[0m stack_clf \u001b[38;5;241m=\u001b[39m StackingClassifier(\n\u001b[0;32m     15\u001b[0m     estimators\u001b[38;5;241m=\u001b[39m[\n\u001b[0;32m     16\u001b[0m         (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mxgb\u001b[39m\u001b[38;5;124m'\u001b[39m, XGBClassifier(tree_method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgpu_hist\u001b[39m\u001b[38;5;124m'\u001b[39m, enable_categorical\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)),\n\u001b[0;32m     17\u001b[0m         (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlgbm\u001b[39m\u001b[38;5;124m'\u001b[39m, LGBMClassifier(n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)),\n\u001b[1;32m---> 18\u001b[0m         (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcat\u001b[39m\u001b[38;5;124m'\u001b[39m, CatBoostClassifier(task_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mGPU\u001b[39m\u001b[38;5;124m'\u001b[39m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, cat_features\u001b[38;5;241m=\u001b[39m[X_resampled\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mget_loc(c) \u001b[38;5;28;01mfor\u001b[39;00m c \u001b[38;5;129;01min\u001b[39;00m category_columns]))\n\u001b[0;32m     19\u001b[0m     ],\n\u001b[0;32m     20\u001b[0m     final_estimator\u001b[38;5;241m=\u001b[39mPipeline([\n\u001b[0;32m     21\u001b[0m         (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mscaler\u001b[39m\u001b[38;5;124m'\u001b[39m, RobustScaler()),\n\u001b[0;32m     22\u001b[0m         (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlr\u001b[39m\u001b[38;5;124m'\u001b[39m, LogisticRegression(max_iter\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1000\u001b[39m, class_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbalanced\u001b[39m\u001b[38;5;124m'\u001b[39m, solver\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mliblinear\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[0;32m     23\u001b[0m     ]),\n\u001b[0;32m     24\u001b[0m     cv\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m,\n\u001b[0;32m     25\u001b[0m     n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m\n\u001b[0;32m     26\u001b[0m )\n\u001b[0;32m     28\u001b[0m \u001b[38;5;66;03m# ✅ 모델 학습\u001b[39;00m\n\u001b[0;32m     29\u001b[0m stack_clf\u001b[38;5;241m.\u001b[39mfit(X_train, y_train)\n",
      "Cell \u001b[1;32mIn[8], line 18\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mcatboost\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m CatBoostClassifier\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# ✅ 모델 구성\u001b[39;00m\n\u001b[0;32m     14\u001b[0m stack_clf \u001b[38;5;241m=\u001b[39m StackingClassifier(\n\u001b[0;32m     15\u001b[0m     estimators\u001b[38;5;241m=\u001b[39m[\n\u001b[0;32m     16\u001b[0m         (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mxgb\u001b[39m\u001b[38;5;124m'\u001b[39m, XGBClassifier(tree_method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgpu_hist\u001b[39m\u001b[38;5;124m'\u001b[39m, enable_categorical\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)),\n\u001b[0;32m     17\u001b[0m         (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlgbm\u001b[39m\u001b[38;5;124m'\u001b[39m, LGBMClassifier(n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)),\n\u001b[1;32m---> 18\u001b[0m         (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcat\u001b[39m\u001b[38;5;124m'\u001b[39m, CatBoostClassifier(task_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mGPU\u001b[39m\u001b[38;5;124m'\u001b[39m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, cat_features\u001b[38;5;241m=\u001b[39m[\u001b[43mX_resampled\u001b[49m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mget_loc(c) \u001b[38;5;28;01mfor\u001b[39;00m c \u001b[38;5;129;01min\u001b[39;00m category_columns]))\n\u001b[0;32m     19\u001b[0m     ],\n\u001b[0;32m     20\u001b[0m     final_estimator\u001b[38;5;241m=\u001b[39mPipeline([\n\u001b[0;32m     21\u001b[0m         (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mscaler\u001b[39m\u001b[38;5;124m'\u001b[39m, RobustScaler()),\n\u001b[0;32m     22\u001b[0m         (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlr\u001b[39m\u001b[38;5;124m'\u001b[39m, LogisticRegression(max_iter\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1000\u001b[39m, class_weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbalanced\u001b[39m\u001b[38;5;124m'\u001b[39m, solver\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mliblinear\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[0;32m     23\u001b[0m     ]),\n\u001b[0;32m     24\u001b[0m     cv\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m,\n\u001b[0;32m     25\u001b[0m     n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m\n\u001b[0;32m     26\u001b[0m )\n\u001b[0;32m     28\u001b[0m \u001b[38;5;66;03m# ✅ 모델 학습\u001b[39;00m\n\u001b[0;32m     29\u001b[0m stack_clf\u001b[38;5;241m.\u001b[39mfit(X_train, y_train)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X_resampled' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "#  1. 데이터 로드 및 전처리\n",
    "train = pd.read_csv('train.csv').drop(columns=['ID'])\n",
    "test = pd.read_csv('test.csv').drop(columns=['ID'])\n",
    "\n",
    "# ✅ train_test_split 오류 해결\n",
    "X = train.drop('임신 성공 여부', axis=1)\n",
    "y = train['임신 성공 여부']\n",
    "\n",
    "# 데이터 분할 (수정된 부분)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "\n",
    "# ✅ 모델 구성\n",
    "stack_clf = StackingClassifier(\n",
    "    estimators=[\n",
    "        ('xgb', XGBClassifier(tree_method='gpu_hist', enable_categorical=True, random_state=42)),\n",
    "        ('lgbm', LGBMClassifier(n_jobs=1, random_state=42, verbose=-1)),\n",
    "        ('cat', CatBoostClassifier(task_type='GPU', verbose=0, cat_features=[X_resampled.columns.get_loc(c) for c in category_columns]))\n",
    "    ],\n",
    "    final_estimator=Pipeline([\n",
    "        ('scaler', RobustScaler()),\n",
    "        ('lr', LogisticRegression(max_iter=1000, class_weight='balanced', solver='liblinear'))\n",
    "    ]),\n",
    "    cv=3,\n",
    "    n_jobs=1\n",
    ")\n",
    "\n",
    "# ✅ 모델 학습\n",
    "stack_clf.fit(X_train, y_train)\n",
    "\n",
    "# ✅ 검증 데이터 평가\n",
    "y_val_pred = stack_clf.predict_proba(X_val)[:, 1]\n",
    "roc_auc = roc_auc_score(y_val, y_val_pred)\n",
    "print(f\"Validation ROC AUC: {roc_auc:.5f}\")\n",
    "\n",
    "# ✅ 테스트 데이터 예측\n",
    "pred_proba = stack_clf.predict_proba(X_test_weighted)[:, 1]\n",
    "\n",
    "# ✅ 결과 저장\n",
    "submission = pd.DataFrame({'ID': [f\"TEST_{i:05d}\" for i in range(len(test))],'probability': pred_proba})\n",
    "submission.to_csv('/content/drive/MyDrive/aimers/submit/final_model_submit.csv', index=False)\n",
    "print(\"제출 파일 생성 완료\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
