{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mre\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_selection\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m train_test_split, RandomizedSearchCV\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m roc_auc_score\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlinear_model\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m LogisticRegression\n",
      "File \u001b[1;32mc:\\Users\\tjddl\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\__init__.py:79\u001b[0m\n\u001b[0;32m     68\u001b[0m     sys\u001b[38;5;241m.\u001b[39mstderr\u001b[38;5;241m.\u001b[39mwrite(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPartial import of sklearn during the build process.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# We are not importing the rest of scikit-learn during the build\u001b[39;00m\n\u001b[0;32m     70\u001b[0m     \u001b[38;5;66;03m# process, as it may not be compiled yet\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     77\u001b[0m     \u001b[38;5;66;03m# later is linked to the OpenMP runtime to make it possible to introspect\u001b[39;00m\n\u001b[0;32m     78\u001b[0m     \u001b[38;5;66;03m# it and importing it first would fail if the OpenMP dll cannot be found.\u001b[39;00m\n\u001b[1;32m---> 79\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     80\u001b[0m         __check_build,  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n\u001b[0;32m     81\u001b[0m         _distributor_init,  \u001b[38;5;66;03m# noqa: F401\u001b[39;00m\n\u001b[0;32m     82\u001b[0m     )\n\u001b[0;32m     83\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m clone\n\u001b[0;32m     84\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_show_versions\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m show_versions\n",
      "File \u001b[1;32mc:\\Users\\tjddl\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\__check_build\\__init__.py:45\u001b[0m\n\u001b[0;32m     31\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\u001b[38;5;124m\"\"\"\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\n\u001b[0;32m     32\u001b[0m \u001b[38;5;124m___________________________________________________________________________\u001b[39m\n\u001b[0;32m     33\u001b[0m \u001b[38;5;124mContents of \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m:\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     40\u001b[0m \u001b[38;5;124m`make` in the source directory.\u001b[39m\n\u001b[0;32m     41\u001b[0m \u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\"\"\u001b[39m \u001b[38;5;241m%\u001b[39m (e, local_dir, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(dir_content)\u001b[38;5;241m.\u001b[39mstrip(), msg))\n\u001b[0;32m     44\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 45\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_check_build\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m check_build  \u001b[38;5;66;03m# noqa\u001b[39;00m\n\u001b[0;32m     46\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     47\u001b[0m     raise_build_error(e)\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:404\u001b[0m, in \u001b[0;36mparent\u001b[1;34m(self)\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import wandb\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "# ğŸŸ¢ WandB í”„ë¡œì íŠ¸ ì´ˆê¸°í™”\n",
    "wandb.init(project=\"xgboost-hyperparam-tuning\", name=\"xgb_experiment\")\n",
    "\n",
    "# ë¬¸ìì—´ â†’ ìˆ«ì ë³€í™˜ í•¨ìˆ˜\n",
    "def convert_count_str(val):\n",
    "    if pd.isna(val):\n",
    "        return 0\n",
    "    val = str(val).strip()\n",
    "    if \"íšŒ ì´ìƒ\" in val:\n",
    "        return 6\n",
    "    m = re.search(r'(\\d+)íšŒ?', val)\n",
    "    if m:\n",
    "        return int(m.group(1))\n",
    "    return 0\n",
    "\n",
    "# ì •ì/ë‚œì ê¸°ì¦ì ë‚˜ì´ ë§µí•‘\n",
    "donor_age_mapping = {\n",
    "    'ë§Œ20ì„¸ ì´í•˜': 3, 'ë§Œ21-25ì„¸': 5, 'ë§Œ26-30ì„¸': 4, 'ë§Œ31-35ì„¸': 2,\n",
    "    'ë§Œ36-40ì„¸': 1, 'ë§Œ41-45ì„¸': 0, 'ì•Œ ìˆ˜ ì—†ìŒ': 0\n",
    "}\n",
    "\n",
    "def convert_donor_age(val):\n",
    "    if pd.isna(val):\n",
    "        return np.nan\n",
    "    return donor_age_mapping.get(str(val).strip(), np.nan)\n",
    "\n",
    "# ì¹´í…Œê³ ë¦¬í˜• ë³€ìˆ˜ NaN ì²˜ë¦¬\n",
    "def convert_nan_to_string(df, category_columns):\n",
    "    df_copy = df.copy()\n",
    "    for col in category_columns:\n",
    "        df_copy[col] = df_copy[col].fillna('NaN')\n",
    "    return df_copy\n",
    "\n",
    "#  1. ë°ì´í„° ë¡œë“œ ë° ì „ì²˜ë¦¬\n",
    "train = pd.read_csv('train.csv').drop(columns=['ID'])\n",
    "test = pd.read_csv('test.csv').drop(columns=['ID'])\n",
    "\n",
    "# ê°€ì¤‘ì¹˜ ë°ì´í„° ë¡œë“œ\n",
    "weight_data = pd.read_csv('og_weighted_hong.csv', encoding='utf-8')\n",
    "weight_dict = weight_data.set_index(\"ë°ì´í„° í•­ëª©\").to_dict()\n",
    "\n",
    "# 'ì‹œìˆ  ë‹¹ì‹œ ë‚˜ì´' ë³€í™˜\n",
    "age_mapping = {\n",
    "    'ë§Œ18-34ì„¸': 5, 'ë§Œ35-37ì„¸': 4, 'ë§Œ38-39ì„¸': 3, 'ë§Œ40-42ì„¸': 2, 'ë§Œ43-44ì„¸': 1, 'ë§Œ45-50ì„¸': 0, 'ì•Œ ìˆ˜ ì—†ìŒ': np.nan\n",
    "}\n",
    "train['ì‹œìˆ  ë‹¹ì‹œ ë‚˜ì´'] = train['ì‹œìˆ  ë‹¹ì‹œ ë‚˜ì´'].apply(lambda x: float(age_mapping.get(str(x).strip(), 0)))\n",
    "test['ì‹œìˆ  ë‹¹ì‹œ ë‚˜ì´'] = test['ì‹œìˆ  ë‹¹ì‹œ ë‚˜ì´'].apply(lambda x: float(age_mapping.get(str(x).strip(), 0)))\n",
    "\n",
    "# íšŸìˆ˜ ê´€ë ¨ ì»¬ëŸ¼ ë³€í™˜\n",
    "count_columns = [\"ì´ ì‹œìˆ  íšŸìˆ˜\", \"í´ë¦¬ë‹‰ ë‚´ ì´ ì‹œìˆ  íšŸìˆ˜\", \"IVF ì‹œìˆ  íšŸìˆ˜\", \"DI ì‹œìˆ  íšŸìˆ˜\",\n",
    "                 \"ì´ ì„ì‹  íšŸìˆ˜\", \"IVF ì„ì‹  íšŸìˆ˜\", \"DI ì„ì‹  íšŸìˆ˜\", \"ì´ ì¶œì‚° íšŸìˆ˜\", \"IVF ì¶œì‚° íšŸìˆ˜\", \"DI ì¶œì‚° íšŸìˆ˜\"]\n",
    "for col in count_columns:\n",
    "    train[col] = train[col].astype(str).apply(convert_count_str).astype(int)\n",
    "    test[col] = test[col].astype(str).apply(convert_count_str).astype(int)\n",
    "\n",
    "# ë‚œì/ì •ì ê¸°ì¦ì ë‚˜ì´ ë³€í™˜\n",
    "train['ë‚œì ê¸°ì¦ì ë‚˜ì´'] = train['ë‚œì ê¸°ì¦ì ë‚˜ì´'].astype(str).apply(convert_donor_age)\n",
    "test['ë‚œì ê¸°ì¦ì ë‚˜ì´'] = test['ë‚œì ê¸°ì¦ì ë‚˜ì´'].astype(str).apply(convert_donor_age)\n",
    "train['ì •ì ê¸°ì¦ì ë‚˜ì´'] = train['ì •ì ê¸°ì¦ì ë‚˜ì´'].astype(str).apply(convert_donor_age)\n",
    "test['ì •ì ê¸°ì¦ì ë‚˜ì´'] = test['ì •ì ê¸°ì¦ì ë‚˜ì´'].astype(str).apply(convert_donor_age)\n",
    "\n",
    "# Feature ê°€ì¤‘ì¹˜ ì ìš©\n",
    "def apply_feature_weights(X, weight_dict):\n",
    "    X_weighted = X.copy()\n",
    "    for column in X.columns:\n",
    "        if column in weight_dict[\"IVF\"]:\n",
    "            X_weighted[column] *= weight_dict[\"IVF\"][column]  # IVF ê°€ì¤‘ì¹˜ ì ìš©\n",
    "    return X_weighted\n",
    "\n",
    "X = train.drop('ì„ì‹  ì„±ê³µ ì—¬ë¶€', axis=1)\n",
    "y = train['ì„ì‹  ì„±ê³µ ì—¬ë¶€']\n",
    "X_weighted = apply_feature_weights(X, weight_dict)\n",
    "X_test_weighted = apply_feature_weights(test, weight_dict)\n",
    "\n",
    "# ë°ì´í„° ë¶ˆê· í˜• ì²˜ë¦¬\n",
    "undersample = RandomUnderSampler(sampling_strategy=0.5, random_state=42)\n",
    "X_resampled, y_resampled = undersample.fit_resample(X_weighted, y)\n",
    "\n",
    "# ë°ì´í„° íƒ€ì… ë³€í™˜\n",
    "category_columns = [\"ì‹œìˆ  ì‹œê¸° ì½”ë“œ\", \"ì‹œìˆ  ìœ í˜•\", \"íŠ¹ì • ì‹œìˆ  ìœ í˜•\", \"ë°°ë€ ìœ ë„ ìœ í˜•\", \"ë°°ì•„ ìƒì„± ì£¼ìš” ì´ìœ \", \"ë‚œì ì¶œì²˜\", \"ì •ì ì¶œì²˜\"]\n",
    "X_resampled = convert_nan_to_string(X_resampled, category_columns)\n",
    "X_test_weighted = convert_nan_to_string(X_test_weighted, category_columns)\n",
    "\n",
    "# í•™ìŠµ/ê²€ì¦ ë°ì´í„° ë¶„í• \n",
    "X_train, X_val, y_train, y_val = train_test_split(X_resampled, y_resampled, test_size=0.2, random_state=42, stratify=y_resampled)\n",
    "\n",
    "# Stacking ëª¨ë¸ ì„¤ì •\n",
    "stack_clf = StackingClassifier(\n",
    "    estimators=[\n",
    "        ('xgb', XGBClassifier(tree_method='gpu_hist', enable_categorical=True, random_state=42)),\n",
    "        ('lgbm', LGBMClassifier(n_jobs=-2, random_state=42, verbose=-1)),\n",
    "        ('cat', CatBoostClassifier(task_type='GPU', verbose=0))\n",
    "    ],\n",
    "    final_estimator=Pipeline([\n",
    "        ('scaler', RobustScaler()),\n",
    "        ('lr', LogisticRegression(max_iter=1000, class_weight='balanced', solver='liblinear'))\n",
    "    ]),\n",
    "    cv=3,\n",
    "    n_jobs=1\n",
    ")\n",
    "\n",
    "# RandomizedSearchCVë¥¼ WandBì™€ í•¨ê»˜ ì‹¤í–‰\n",
    "param_dist = {\n",
    "    'xgb__n_estimators': [300, 400, 500],\n",
    "    'xgb__max_depth': [4, 5, 6],\n",
    "    'xgb__learning_rate': [0.025, 0.05, 0.1],\n",
    "    'final_estimator__lr__C': [0.1, 1.0, 5.0, 10.0]\n",
    "}\n",
    "\n",
    "random_search = RandomizedSearchCV(stack_clf, param_distributions=param_dist, n_iter=10, scoring='roc_auc', cv=3, n_jobs=1, random_state=42, verbose=2)\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "# ê²°ê³¼ ë¡œê¹…\n",
    "wandb.log({\"Best ROC AUC\": random_search.best_score_})\n",
    "print(f\"Best Validation ROC AUC: {random_search.best_score_:.5f}\")\n",
    "\n",
    "# í…ŒìŠ¤íŠ¸ ë°ì´í„° ì˜ˆì¸¡\n",
    "pred_proba = random_search.best_estimator_.predict_proba(X_test_weighted)[:, 1]\n",
    "submission = pd.DataFrame({'ID': [f\"TEST_{i:05d}\" for i in range(len(test))], 'probability': pred_proba})\n",
    "submission.to_csv('Result_submit.csv', index=False)\n",
    "print(\"ì œì¶œ íŒŒì¼ ìƒì„± ì™„ë£Œ\")\n",
    "\n",
    "wandb.finish()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
